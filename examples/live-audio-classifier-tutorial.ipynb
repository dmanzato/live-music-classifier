{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Audio Classification Tutorial\n",
        "\n",
        "This notebook demonstrates how to use the audio_classify library for:\n",
        "1. Loading and preprocessing audio data\n",
        "2. Training a model\n",
        "3. Running inference\n",
        "4. Visualizing results\n",
        "\n",
        "**Prerequisites:**\n",
        "- UrbanSound8K dataset downloaded and extracted\n",
        "- Update `DATA_ROOT` below with your dataset path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add parent directory to path\n",
        "sys.path.insert(0, str(Path().absolute().parent))\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets.urbansound8k import UrbanSound8K\n",
        "from models.small_cnn import SmallCNN\n",
        "from transforms.audio import get_mel_transform, wav_to_logmel\n",
        "from utils.device import get_device, get_device_name\n",
        "\n",
        "# Configuration\n",
        "DATA_ROOT = \"/path/to/UrbanSound8K\"  # Update this!\n",
        "DEVICE = get_device()\n",
        "print(f\"Using device: {get_device_name()} ({DEVICE})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Dataset\n",
        "\n",
        "Load a subset of the UrbanSound8K dataset (e.g., fold 10 for validation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = UrbanSound8K(\n",
        "    root=DATA_ROOT,\n",
        "    folds=[10],  # Use fold 10 for validation\n",
        "    target_sr=16000,\n",
        "    duration=4.0,\n",
        "    n_mels=64,\n",
        "    n_fft=1024,\n",
        "    hop_length=256,\n",
        "    augment=None  # No augmentation for visualization\n",
        ")\n",
        "\n",
        "print(f\"Dataset size: {len(dataset)}\")\n",
        "print(f\"Number of classes: {len(dataset.class_ids)}\")\n",
        "print(f\"Class names: {list(dataset.idx2name.values())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Inspect a Sample\n",
        "\n",
        "Load and visualize a single sample from the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a sample\n",
        "idx = 0\n",
        "log_mel, label = dataset[idx]\n",
        "\n",
        "print(f\"Sample {idx}:\")\n",
        "print(f\"  Log-mel shape: {log_mel.shape}\")\n",
        "print(f\"  Label index: {label}\")\n",
        "print(f\"  Class name: {dataset.idx2name[label]}\")\n",
        "\n",
        "# Visualize spectrogram\n",
        "plt.figure(figsize=(10, 4))\n",
        "arr = log_mel.squeeze(0).detach().cpu().numpy()\n",
        "plt.imshow(arr, aspect='auto', origin='lower')\n",
        "plt.title(f\"Log-Mel Spectrogram: {dataset.idx2name[label]}\")\n",
        "plt.xlabel(\"Time frames\")\n",
        "plt.ylabel(\"Mel bins\")\n",
        "plt.colorbar(label=\"dB\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create and Test Model\n",
        "\n",
        "Create a SmallCNN model and test the forward pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "num_classes = len(dataset.class_ids)\n",
        "model = SmallCNN(n_classes=num_classes).to(DEVICE)\n",
        "\n",
        "# Test forward pass\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    x = log_mel.unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
        "    logits = model(x)\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "print(f\"Model output shape: {logits.shape}\")\n",
        "print(f\"\\nTop 3 predictions:\")\n",
        "top3_probs, top3_indices = torch.topk(probs[0], k=3)\n",
        "for i, (prob, idx) in enumerate(zip(top3_probs, top3_indices)):\n",
        "    class_name = dataset.idx2name[int(idx)]\n",
        "    print(f\"  {i+1}. {class_name}: {prob:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Trained Model (if available)\n",
        "\n",
        "Load a pre-trained model checkpoint for inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHECKPOINT_PATH = \"artifacts/best_model.pt\"\n",
        "\n",
        "try:\n",
        "    state_dict = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    print(f\"Loaded model from {CHECKPOINT_PATH}\")\n",
        "    \n",
        "    # Run inference on sample\n",
        "    with torch.no_grad():\n",
        "        x = log_mel.unsqueeze(0).to(DEVICE)\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "    \n",
        "    print(f\"\\nPredictions for sample (true label: {dataset.idx2name[label]}):\")\n",
        "    top5_probs, top5_indices = torch.topk(probs[0], k=5)\n",
        "    for i, (prob, idx) in enumerate(zip(top5_probs, top5_indices)):\n",
        "        class_name = dataset.idx2name[int(idx)]\n",
        "        is_correct = \"âœ“\" if int(idx) == label else \"\"\n",
        "        print(f\"  {i+1}. {class_name}: {prob:.3f} {is_correct}\")\n",
        "        \n",
        "except FileNotFoundError:\n",
        "    print(f\"Model checkpoint not found at {CHECKPOINT_PATH}\")\n",
        "    print(\"Train a model first using: python train.py --data_root <path> --epochs 5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "- Train your own model: `python train.py --data_root <path> --epochs 5`\n",
        "- Run inference on files: `python predict.py --wav <file> --data_root <path>`\n",
        "- Try live streaming: `python scripts/stream_infer.py --data_root <path>`\n",
        "- Explore the dataset: `python scripts/vis_dataset.py --data_root <path>`\n",
        "\n",
        "For more examples, see the [examples/](../examples/) directory.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
